---
layout: archive
title: ""
permalink: /projects/
author_profile: true
---


{% include base_path %}

<h2><i style="font-size:24px" class="fa">&#xf013;</i> Latest Project:</h2>
<p style="text-align: center;"><span style="color: orange;"><strong>Electroencephalography-Based Human Emotion Prediction Using Deep Learning</strong></span></p>
<p align="center">
  <img width="600" height="179" src="https://user-images.githubusercontent.com/107177894/173532032-a972cb69-ed93-4452-bdf9-c37462af5fb7.png">
</p>

<p align="center"><button onclick="myFunction20()" id="myBtn20" 
                          style= "background-color: #112232; color: white; border: 2px solid #7FFFD4; font-size: 16px"> Read More</button></p>
 

 
<span id="dots20"></span><span id="more20">

 <script>
  if (document.getElementById("dots20").style.display != "none"){
  document.getElementById("dots20").style.display = "inline";
  document.getElementById("more20").style.display = "none";
  }
 </script>


<p>This is project for fulfilment of the course &quot;Brain Computer Interfaces: Fundamentals and Application&quot;.</p>
<p><u>Project Aims &amp; Objectives:</u></p>
<p align="justify">The goal of this project is to provide electroencephalography (EEG) approaches for emotion recognition. EEG signals are collected from the brain&rsquo;s scalp and analyzed in response to a variety of stimuli representing the three main emotions. Human emotions are varied and complex but can be generalized into positive, neutral, and negative categories.</p>
<p align="center"><img width="500" height="292" src="images/VLM6D_Point_Cloud.png"></p></span>

<script>
function myFunction20() {
  var dots = document.getElementById("dots20");
  var moreText = document.getElementById("more20");
  var btnText = document.getElementById("myBtn20");

  if (dots.style.display === "none") {
    dots.style.display = "inline";
    btnText.innerHTML = " Read More"; 
    moreText.style.display = "none";
  } else {
    dots.style.display = "none";
    btnText.innerHTML = " Read Less"; 
    moreText.style.display = "inline";
  }
}
</script>


  
<p><i class="fab fa-github" style="color:Aquamarine"></i> <a href="https:/" style="color: Aquamarine; text-decoration:none;" target="\_blank">Repository</a></p>
<br>



<p style="text-align: center;"><span style="color: orange;"><strong>VLM6D: VLM based 6Dof Pose Estimation based on RGB-D Images</strong></span></p>
<p align="center">
  <img width="400" height="299" src="https://user-images.githubusercontent.com/107177894/174438161-5a8156dd-c66c-49c6-970b-c7e1a04edf34.png">
</p>

<p align="center"><button onclick="myFunction10()" id="myBtn10" 
                           style= "background-color: #112232; color: white; border: 2px solid #7FFFD4; font-size: 16px"> Read More</button></p>
 

 
<span id="dots10"></span><span id="more10">

 <script>
  if (document.getElementById("dots10").style.display != "none"){
  document.getElementById("dots10").style.display = "inline";
  document.getElementById("more10").style.display = "none";
  }
 </script>

<p><u>Project Aims &amp; Objectives:</u></p>
<p align="justify">VLM6D, a novel dual-stream architecture that leverages the distinct strengths of visual and geometric data from RGB-D input for robust and precise pose estimation. Our framework uniquely integrates two specialized encoders: a powerful, self-supervised Vision Transformer (DINOv2) processes the RGB modality, harnessing its rich, pre-trained understanding of visual grammar to achieve remarkable resilience against texture and lighting variations. Concurrently, a PointNet++ encoder processes the 3D point cloud derived from depth data, enabling robust geometric reasoning that excels even with the sparse, fragmented data typical of severe occlusion. </p>
<p align="center"><img width="388" height="264" src="https://user-images.githubusercontent.com/107177894/174438231-7a63a268-0c33-46b9-8ea5-8a76fbbf0dfa.png"></p></span>

<script>
function myFunction10() {
  var dots = document.getElementById("dots10");
  var moreText = document.getElementById("more10");
  var btnText = document.getElementById("myBtn10");

  if (dots.style.display === "none") {
    dots.style.display = "inline";
    btnText.innerHTML = " Read More"; 
    moreText.style.display = "none";
  } else {
    dots.style.display = "none";
    btnText.innerHTML = " Read Less"; 
    moreText.style.display = "inline";
  }
}
</script>
  
<p><i class="fab fa-github" style="color:Aquamarine"></i> <a href="https://" style="color: Aquamarine; text-decoration:none;" target="\_blank">Repository</a></p>



<!DOCTYPE html>
<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1">
<style>
.collapsible {
  background-color: #252b35;
  color: white;
  cursor: pointer;
  padding: 18px;
  width: 100%;
  border: ridge;
  text-align: left;
  outline: none;
  font-size: 15px;
}

.active, .collapsible:hover {
  background-color: #252b35;
}

.collapsible:after {
  content: '\002B';
  color: white;
  font-weight: bold;
  float: right;
  margin-left: 5px;
}

.active:after {
  content: "\2212";
}

.content {
  padding: 0 18px;
  max-height: 0;
  overflow: hidden;
  transition: max-height 0.2s ease-out;
  background-color: #0a0000
;
}
</style>
</head>
<body>

<!DOCTYPE html>
<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1">
<style>
.collapsible {
  background-color: #252b35;
  color: white;
  cursor: pointer;
  padding: 18px;
  width: 100%;
  border: ridge
  text-align: left;
  outline: none;
  font-size: 15px;
}

.active, .collapsible:hover {
  background-color: #112232 ;
  color: white;
}

.collapsible:after {
  content: white;
  color: #252b35
  font-weight: bold;
  float: right;
  margin-left: 5px;
}

.active:after {
  content: "\2212";
}

.content {
  padding: 0 18px;
  max-height: 0;
  overflow: hidden;
  transition: max-height 0.2s ease-out;
  background-color: #112232 
;
}
</style>
</head>
<body>

 <h2><i style="font-size:24px" class="fa">&#xf085;</i> Industrial & Research Institute collaboration Projects:</h2>
<button class="collapsible"> <strong>RISE</strong> (Funding by Nanosystem ltd, SK telecom, kakao Inc, ETRI AI etc..), Korea</button>
<div class="content">
 <ul>
<li>3D Human Pose Estimation with VLM integration for LiDAR & RADAR fusion for workers safety and Industry automation (<strong>Project-1</strong>)</li>
<li> 3D Object Pose Estimation and Object Tracking using VLMs to manipulate Mobile Robot (<strong> Project-2</strong>)</li>
</ul>
    
</div>
<button class="collapsible"> <strong>SL Corp. (Automotive), Korea </strong> </button>
<div class="content">
 <ul>
<li> 3D Object Pose Estimation and Tracking using VLMs to manipulate Mobile Robot (<strong> Project</strong>)</li>
</ul>
</div>
<button class="collapsible"> <strong>RLRC </strong> (Regional Leading Research Center), South Korea</button>
<div class="content">
<ul>
<li> 3D Human Pose Estimation with VLM integration and Robot Manipulation for Healthcare (<strong>Project </strong>)</li>
</ul>
</div>


<script>
var coll = document.getElementsByClassName("collapsible");
var i;

for (i = 0; i < coll.length; i++) {
  coll[i].addEventListener("click", function() {
    this.classList.toggle("active");
    var content = this.nextElementSibling;
    if (content.style.maxHeight){
      content.style.maxHeight = null;
    } else {
      content.style.maxHeight = content.scrollHeight + "px";
    } 
  });
}
</script>

</body>
</html>

<h2><i class='fas fa-pencil-ruler' style='font-size:20px'></i> Skills:</h2>     
<br> 
  
<table style="margin-right: calc(50%); width: 100%;">
    <thead>
        <tr>
            <th style="background-color:#112232">Framework/Library</th>
            <th style="background-color:#112232">Software/Research</th>
            <th style="background-color:#112232">Language</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>PyTorch</td>
            <td>Python</td>
            <td>Bengali: Native</td>
        </tr>
        <tr>
            <td>ROS(Robot Operating System)</td>
            <td>Multi Modal</td>
            <td>English: Fluent</td>
        </tr>
        <tr>
            <td>TensorFlow</td>
            <td>LaTeX</td>
            <td>Korean: Intermediate</td>
        </tr>
        <tr>
            <td>Matplotlib</td>
            <td>Vision Transformer(ViT)</td>
            <td>Hindi: Fluent</td>
        </tr>
        <tr>
            <td>YOLOv8</td>
            <td>LLM</td>
            <td>Chinese (Mandarin): Elementary</td>
        </tr>
        <tr>
            <td>Detectron2</td>
            <td>VLM</td>
            <td><br></td>
        </tr>
        <tr>
            <td>OpenMMLab</td>
            <td>LiDAR sensor</td>
            <td><br></td>
        </tr>
        <tr>
            <td>OpenCV</td>
            <td><br></td>
            <td><br></td>
        </tr>
    </tbody>
</table>


<h2><i style="font-size:24px" class="fa">&#xf15c;</i>  <a href="https://drive.google.com/drive/folders/1IhelAGlwlUyQ4z2BGqwHXrKYfooh21Rr" target="\_blank" style="color: #A7EEF3; text-decoration:none">Certifications (MOOC & Workshops)</a>.</h2>

